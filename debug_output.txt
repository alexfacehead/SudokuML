Epoch # 0
Puzzle # 1

Remembering experience:
        State: [[8 6 4 3 7 1 2 5 9]
 [3 2 5 8 4 9 7 6 1]
 [9 7 1 2 6 0 8 4 3]
 [0 3 6 0 9 2 5 8 0]
 [1 9 8 6 5 7 0 3 2]
 [2 5 7 4 8 3 9 1 6]
 [6 8 9 7 3 0 1 2 5]
 [7 1 3 0 2 8 0 9 4]
 [5 4 2 9 1 6 3 7 8]]
        Action: (3, 3, 1)
        Reward: -5
        Next state: [[8 6 4 3 7 1 2 5 9]
 [3 2 5 8 4 9 7 6 1]
 [9 7 1 2 6 0 8 4 3]
 [0 3 6 1 9 2 5 8 0]
 [1 9 8 6 5 7 0 3 2]
 [2 5 7 4 8 3 9 1 6]
 [6 8 9 7 3 0 1 2 5]
 [7 1 3 0 2 8 0 9 4]
 [5 4 2 9 1 6 3 7 8]]
        Done: False
        Memory size: 1
        Batch size: 20
state_batch shape: (1, 9, 9, 1)
action_batch shape: (1, 3)
reward_batch shape: (1, 1)
next_state_batch shape: (1, 9, 9, 1)
done_batch shape: (1, 1)
next_q_values shape: (1, 9, 9, 9)
current_q_values shape: (1, 9, 9, 9)
next_q_values_selected shape: (1,)
target_q_values shape (before squeezing): (1, 1)
target_q_values shape (after squeezing): (1,)
target_q_values shape (after expanding dimensions): (1, 1, 1, 1)
mask shape: (1, 9, 9, 9)
target_q_values shape (after applying mask): (1, 9, 9, 9)
target_q_values shape (after reshaping): (1, 729)
Running total step #0
Puzzle step # 0
Chosen action: (3, 3, 1)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #1
Puzzle step # 1
Chosen action: (4, 6, 4)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #2
Puzzle step # 2
Chosen action: (6, 5, 4)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Running total step #3
Puzzle step # 3
Chosen action: (7, 3, 5)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Puzzle # 2
Running total step #4
Puzzle step # 0
Chosen action: (0, 5, 9)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #5
Puzzle step # 1
Chosen action: (5, 2, 3)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #6
Puzzle step # 2
Chosen action: (0, 7, 5)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Running total step #7
Puzzle step # 3
Chosen action: (5, 3, 7)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Puzzle # 3
Running total step #8
Puzzle step # 0
Chosen action: (7, 6, 2)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #9
Puzzle step # 1
Chosen action: (3, 8, 9)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #10
Puzzle step # 2
Chosen action: (6, 6, 4)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Running total step #11
Puzzle step # 3
Chosen action: (0, 3, 1)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Running total step #12
Puzzle step # 4
Chosen action: (4, 5, 1)
Reward: -5
Episode reward: -25

Exploration rate (epsilon): 1.0
Running total step #13
Puzzle step # 5
Chosen action: (6, 3, 6)
Reward: -5
Episode reward: -30

Exploration rate (epsilon): 1.0
Puzzle # 4
Running total step #14
Puzzle step # 0
Chosen action: (8, 0, 5)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #15
Puzzle step # 1
Chosen action: (7, 8, 4)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #16
Puzzle step # 2
Chosen action: (4, 1, 7)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Running total step #17
Puzzle step # 3
Chosen action: (3, 2, 9)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Running total step #18
Puzzle step # 4
Chosen action: (8, 7, 6)
Reward: -5
Episode reward: -25

Exploration rate (epsilon): 1.0
Running total step #19
Puzzle step # 5
Chosen action: (3, 0, 6)
Reward: -5
Episode reward: -30

Exploration rate (epsilon): 1.0
Puzzle # 5
Running total step #20
Puzzle step # 0
Chosen action: (3, 3, 6)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #21
Puzzle step # 1
Chosen action: (5, 4, 9)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #22
Puzzle step # 2
Chosen action: (8, 3, 7)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Running total step #23
Puzzle step # 3
Chosen action: (6, 5, 4)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Running total step #24
Puzzle step # 4
Chosen action: (6, 6, 9)
Reward: -5
Episode reward: -25

Exploration rate (epsilon): 1.0
Running total step #25
Puzzle step # 5
Chosen action: (5, 0, 2)
Reward: -5
Episode reward: -30

Exploration rate (epsilon): 1.0
Puzzle # 6
Running total step #26
Puzzle step # 0
Chosen action: (2, 6, 4)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #27
Puzzle step # 1
Chosen action: (5, 0, 7)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #28
Puzzle step # 2
Chosen action: (0, 0, 1)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Running total step #29
Puzzle step # 3
Chosen action: (6, 6, 7)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Puzzle # 7
Running total step #30
Puzzle step # 0
Chosen action: (5, 5, 2)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #31
Puzzle step # 1
Chosen action: (6, 2, 2)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #32
Puzzle step # 2
Chosen action: (5, 4, 5)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Running total step #33
Puzzle step # 3
Chosen action: (5, 6, 1)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Puzzle # 8
Running total step #34
Puzzle step # 0
Chosen action: (4, 4, 8)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #35
Puzzle step # 1
Chosen action: (3, 0, 5)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #36
Puzzle step # 2
Chosen action: (1, 1, 6)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Running total step #37
Puzzle step # 3
Chosen action: (1, 6, 1)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Running total step #38
Puzzle step # 4
Chosen action: (4, 5, 7)
Reward: -5
Episode reward: -25

Exploration rate (epsilon): 1.0
Puzzle # 9
Running total step #39
Puzzle step # 0
Chosen action: (0, 1, 6)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #40
Puzzle step # 1
Chosen action: (2, 4, 9)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #41
Puzzle step # 2
Chosen action: (8, 4, 2)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0

Remembering experience:
        State: [[5 6 3 0 7 2 1 9 8]
 [2 1 9 0 8 6 7 5 4]
 [8 4 7 1 9 5 6 2 0]
 [4 7 2 6 3 8 5 1 0]
 [9 5 1 2 4 7 3 8 6]
 [6 3 8 5 1 9 4 7 2]
 [7 9 5 8 6 4 2 0 1]
 [3 2 4 9 5 1 8 6 7]
 [1 8 6 7 2 3 9 4 5]]
        Action: (1, 3, 3)
        Reward: -5
        Next state: [[5 6 3 0 7 2 1 9 8]
 [2 1 9 3 8 6 7 5 4]
 [8 4 7 1 9 5 6 2 0]
 [4 7 2 6 3 8 5 1 0]
 [9 5 1 2 4 7 3 8 6]
 [6 3 8 5 1 9 4 7 2]
 [7 9 5 8 6 4 2 0 1]
 [3 2 4 9 5 1 8 6 7]
 [1 8 6 7 2 3 9 4 5]]
        Done: False
        Memory size: 51
        Running total step #42
Puzzle step # 3
Chosen action: (1, 3, 3)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Puzzle # 10
Running total step #43
Puzzle step # 0
Chosen action: (0, 7, 4)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #44
Puzzle step # 1
Chosen action: (3, 7, 2)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #45
Puzzle step # 2
Chosen action: (2, 0, 7)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Puzzle # 11
Running total step #46
Puzzle step # 0
Chosen action: (8, 3, 7)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 1.0
Running total step #47
Puzzle step # 1
Chosen action: (4, 2, 6)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 1.0
Running total step #48
Puzzle step # 2
Chosen action: (3, 2, 9)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 1.0
Running total step #49
Puzzle step # 3
Chosen action: (7, 2, 7)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 1.0
Batch size: 20
state_batch shape: (20, 9, 9, 1)
action_batch shape: (20, 3)
reward_batch shape: (20, 1)
next_state_batch shape: (20, 9, 9, 1)
done_batch shape: (20, 1)
next_q_values shape: (20, 9, 9, 9)
current_q_values shape: (20, 9, 9, 9)
next_q_values_selected shape: (20,)
target_q_values shape (before squeezing): (20, 1)
target_q_values shape (after squeezing): (20,)
target_q_values shape (after expanding dimensions): (20, 1, 1, 1)
mask shape: (20, 9, 9, 9)
target_q_values shape (after applying mask): (20, 9, 9, 9)
target_q_values shape (after reshaping): (20, 729)
Running total step #50
Puzzle step # 4
Chosen action: (0, 2, 4)
Reward: -5
Episode reward: -25

Exploration rate (epsilon): 0.9950000047683716
Puzzle # 12
Running total step #51
Puzzle step # 0
Chosen action: (2, 5, 9)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 0.9950000047683716
Running total step #52
Puzzle step # 1
Chosen action: (6, 6, 4)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 0.9950000047683716
Running total step #53
Puzzle step # 2
Chosen action: (8, 3, 6)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 0.9950000047683716
Running total step #54
Puzzle step # 3
Chosen action: (5, 6, 8)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 0.9950000047683716
Running total step #55
Puzzle step # 4
Chosen action: (4, 5, 8)
Reward: -5
Episode reward: -25

Exploration rate (epsilon): 0.9950000047683716
Puzzle # 13
Running total step #56
Puzzle step # 0
Chosen action: (5, 7, 2)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 0.9950000047683716
Running total step #57
Puzzle step # 1
Chosen action: (5, 4, 7)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 0.9950000047683716
Running total step #58
Puzzle step # 2
Chosen action: (7, 4, 4)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 0.9950000047683716
Running total step #59
Puzzle step # 3
Chosen action: (7, 7, 1)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 0.9950000047683716
Running total step #60
Puzzle step # 4
Chosen action: (3, 7, 4)
Reward: -5
Episode reward: -25

Exploration rate (epsilon): 0.9950000047683716
Puzzle # 14
Running total step #61
Puzzle step # 0
Chosen action: (2, 4, 5)
Reward: -5
Episode reward: -5

Exploration rate (epsilon): 0.9950000047683716
Running total step #62
Puzzle step # 1
Chosen action: (1, 1, 2)
Reward: -5
Episode reward: -10

Exploration rate (epsilon): 0.9950000047683716
Running total step #63
Puzzle step # 2
Chosen action: (3, 1, 7)
Reward: -5
Episode reward: -15

Exploration rate (epsilon): 0.9950000047683716
Running total step #64
Puzzle step # 3
Chosen action: (1, 6, 7)
Reward: -5
Episode reward: -20

Exploration rate (epsilon): 0.9950000047683716
Running total step #65
Puzzle step # 4
Chosen action: (0, 8, 3)
Reward: -5
Episode reward: -25

Exploration rate (epsilon): 0.9950000047683716
Puzzle # 15
